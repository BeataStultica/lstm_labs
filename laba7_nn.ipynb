{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "laba7_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4M/n5BjgarkAKkmX5C3eO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeataStultica/lstm_labs/blob/main/laba7_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r-8V_01Up6bm"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "import re\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOiRSWrnxS1G",
        "outputId": "3565e579-99bf-4363-a51d-c2a0a369a13a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_json('/content/gdrive/MyDrive/yelp_academic_dataset_review.json', lines=True)\n",
        "#df.head\n",
        "data = []\n",
        "column = ['stars', 'text']\n",
        "with open('/content/gdrive/MyDrive/yelp_academic_dataset_review.json', encoding='latin-1') as f:\n",
        "  for line in f:\n",
        "    st = json.loads(line)\n",
        "    out_line = [st['text'], st['stars']]\n",
        "    data.append(out_line)\n"
      ],
      "metadata": {
        "id": "a6luKcbPw3Z4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=data, columns= column)\n",
        "df.columns = ['text', 'stars']\n",
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdCGHtsG_yYD",
        "outputId": "5d81b2b1-2386-4695-b53b-2347a43d72f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                       text  stars\n",
              "0        If you decide to eat here, just be aware it is...    3.0\n",
              "1        I've taken a lot of spin classes over the year...    5.0\n",
              "2        Family diner. Had the buffet. Eclectic assortm...    3.0\n",
              "3        Wow!  Yummy, different,  delicious.   Our favo...    5.0\n",
              "4        Cute interior and owner (?) gave us tour of up...    4.0\n",
              "...                                                    ...    ...\n",
              "6990275  Latest addition to services from ICCU is Apple...    5.0\n",
              "6990276  This spot offers a great, affordable east week...    5.0\n",
              "6990277  This Home Depot won me over when I needed to g...    4.0\n",
              "6990278  For when I'm feeling like ignoring my calorie-...    5.0\n",
              "6990279  Located in the 'Walking District' in Nashville...    3.0\n",
              "\n",
              "[6990280 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['text', 'stars']][:1000000]\n",
        "embed_dim = 128\n",
        "lstm_out = 256\n",
        "batch_size= 128\n",
        "n_epoch = 5\n",
        "word_count = 20000\n",
        "\n",
        "data['sentiment']=[1 if (x>3) else 0 for x in data['stars']]\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "#for idx,row in data.iterrows():\n",
        "#    row[0] = row[0].replace('rt',' ')\n",
        "#data['text']= [x.encode('ascii') for x in data['text']]\n",
        "\n",
        "tokenizer = Tokenizer(nb_words = word_count, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X, maxlen=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naButi3trNBe",
        "outputId": "3db39a98-87e0-4d56-e94a-7aa71bf18755"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0DsEeSrd7n8",
        "outputId": "e35d32e7-d99f-43b3-a942-cd34886f1bf0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                      text  stars  sentiment\n",
              "0       if you decide to eat here just be aware it is ...    3.0          0\n",
              "1       ive taken a lot of spin classes over the years...    5.0          1\n",
              "2       family diner had the buffet eclectic assortmen...    3.0          0\n",
              "3       wow  yummy different  delicious   our favorite...    5.0          1\n",
              "4       cute interior and owner  gave us tour of upcom...    4.0          1\n",
              "...                                                   ...    ...        ...\n",
              "999995  never really had any issues here other than th...    3.0          0\n",
              "999996  fish recently moved a couple of doors down the...    4.0          1\n",
              "999997  ive been to south house around a dozen or so t...    3.0          0\n",
              "999998  wow i am shocked at these reviews i have tried...    1.0          0\n",
              "999999  headed to st louis for a little getaway with m...    4.0          1\n",
              "\n",
              "[1000000 rows x 3 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(20000, 100, input_length = 50))#word_count, embed_dim,input_length = 50))#X.shape[1]))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "\n",
        "Y = data['sentiment']#pd.get_dummies(data['sentiment']).values\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size = 0.20, random_state = 21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uUMsRq2rqbI",
        "outputId": "0b56f26d-5d75-4a3e-e7ae-e1a274c79666"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model_path = '/content/gdrive/MyDrive/last_model_lab7.h5'\n",
        "callback = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True)\n",
        "model.fit(X_train, Y_train, batch_size =batch_size, epochs = n_epoch, validation_data=(X_valid, Y_valid), \n",
        "          steps_per_epoch=len(X_train)//batch_size, validation_steps=len(X_valid)//batch_size, callbacks = [callback])\n",
        "\n",
        "\n",
        "#score,acc = model.evaluate(X_valid, Y_valid, batch_size = batch_size)\n",
        "#print(\"Logloss score: %.2f\" % (score))\n",
        "#print(\"Validation set Accuracy: %.2f\" % (acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8C4c25Krwt_",
        "outputId": "641d40bb-f4d0-402c-a270-86274a48e1f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6250/6250 [==============================] - 603s 96ms/step - loss: 0.2550 - accuracy: 0.8951 - val_loss: 0.2293 - val_accuracy: 0.9063\n",
            "Epoch 2/5\n",
            "6250/6250 [==============================] - 621s 99ms/step - loss: 0.2106 - accuracy: 0.9154 - val_loss: 0.2225 - val_accuracy: 0.9109\n",
            "Epoch 3/5\n",
            "6250/6250 [==============================] - 605s 97ms/step - loss: 0.1908 - accuracy: 0.9241 - val_loss: 0.2200 - val_accuracy: 0.9123\n",
            "Epoch 4/5\n",
            "6250/6250 [==============================] - 587s 94ms/step - loss: 0.1737 - accuracy: 0.9311 - val_loss: 0.2261 - val_accuracy: 0.9120\n",
            "Epoch 5/5\n",
            "6250/6250 [==============================] - 583s 93ms/step - loss: 0.1584 - accuracy: 0.9377 - val_loss: 0.2413 - val_accuracy: 0.9100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1309711b10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model2 = load_model('/content/gdrive/MyDrive/last_model_lab7.h5')\n",
        "text = [\"I hate this service, return my money\", \"Nice book, i will recommend it to my friends\"]\n",
        "for i in text:\n",
        "  sequence = tokenizer.texts_to_sequences([i])\n",
        "  data = pad_sequences(sequence, maxlen=50)\n",
        "  result = model2.predict(data)\n",
        "  print(result)\n",
        "  if result[0][0] <0.5:\n",
        "    print('negative')\n",
        "  else:\n",
        "    print('positive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vCzUxBbg42y",
        "outputId": "d2967c69-ba5c-4b5e-d544-13af23f39bc5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "[[0.11892862]]\n",
            "negative\n",
            "[[0.9699573]]\n",
            "positive\n"
          ]
        }
      ]
    }
  ]
}